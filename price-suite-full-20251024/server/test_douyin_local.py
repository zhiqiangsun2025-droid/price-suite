#!/usr/bin/env python3
"""
æŠ–åº—çˆ¬è™«æœ¬åœ°æµ‹è¯•è„šæœ¬
å¯ä»¥ç›´è§‚çœ‹åˆ°æµè§ˆå™¨æ“ä½œè¿‡ç¨‹
"""

from douyin_scraper_v2 import DouyinScraperV2
import time

def main():
    print("=" * 60)
    print("æŠ–åº—çˆ¬è™«æµ‹è¯• - æœ¬åœ°æµ‹è¯•æ¨¡å¼")
    print("=" * 60)
    
    # éheadlessæ¨¡å¼ï¼ˆå¯ä»¥çœ‹åˆ°æµè§ˆå™¨ï¼‰
    scraper = DouyinScraperV2(headless=False)
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        print("\nâœ… åˆå§‹åŒ–æµè§ˆå™¨...")
        scraper.init_driver()
        print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼")
        
        # å¼€å§‹ç™»å½•
        print("\nğŸ”„ å¼€å§‹ç™»å½•æŠ–åº—...")
        print("   é‚®ç®±ï¼šdoudianpuhuo3@163.com")
        print("   å¯†ç ï¼šPing99re.com")
        
        status, message = scraper.start_login(
            'doudianpuhuo3@163.com',
            'Ping99re.com'
        )
        
        print(f"\nç™»å½•çŠ¶æ€ï¼š{status}")
        print(f"æç¤ºä¿¡æ¯ï¼š{message}")
        
        # æµ‹è¯•æˆªå›¾åŠŸèƒ½
        print("\nğŸ“¸ æµ‹è¯•æˆªå›¾åŠŸèƒ½...")
        screenshot_base64 = scraper.take_screenshot(max_width=800)
        if screenshot_base64:
            print(f"âœ… æˆªå›¾æˆåŠŸï¼Base64é•¿åº¦ï¼š{len(screenshot_base64)} å­—ç¬¦")
            
            # ä¿å­˜æˆªå›¾åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰
            import base64
            from PIL import Image
            from io import BytesIO
            
            img_data = base64.b64decode(screenshot_base64)
            img = Image.open(BytesIO(img_data))
            img.save('test_screenshot.png')
            print("âœ… æˆªå›¾å·²ä¿å­˜ï¼štest_screenshot.png")
        else:
            print("âŒ æˆªå›¾å¤±è´¥")
        
        # å¦‚æœéœ€è¦éªŒè¯ç 
        if status == 'need_code':
            print("\nğŸ“§ éœ€è¦éªŒè¯ç ï¼")
            print("è¯·å»é‚®ç®± doudianpuhuo3@163.com æŸ¥çœ‹éªŒè¯ç ")
            
            code = input("\nè¯·è¾“å…¥éªŒè¯ç ï¼š")
            
            if code:
                print("\nğŸ”„ æäº¤éªŒè¯ç ...")
                success, msg = scraper.submit_verification_code(code)
                print(f"ç»“æœï¼š{msg}")
                
                if success:
                    print("\nâœ… ç™»å½•æˆåŠŸï¼")
                    
                    # å†æ¬¡æˆªå›¾
                    print("\nğŸ“¸ ç™»å½•æˆåŠŸåæˆªå›¾...")
                    screenshot_base64 = scraper.take_screenshot()
                    if screenshot_base64:
                        print(f"âœ… æˆªå›¾æˆåŠŸï¼Base64é•¿åº¦ï¼š{len(screenshot_base64)} å­—ç¬¦")
                        
                        img_data = base64.b64decode(screenshot_base64)
                        img = Image.open(BytesIO(img_data))
                        img.save('test_screenshot_logged_in.png')
                        print("âœ… æˆªå›¾å·²ä¿å­˜ï¼štest_screenshot_logged_in.png")
        
        elif status == 'success':
            print("\nâœ… ç™»å½•æˆåŠŸï¼ˆæ— éœ€éªŒè¯ç ï¼‰ï¼")
        
        # å¦‚æœç™»å½•æˆåŠŸï¼Œæµ‹è¯•è·³è½¬
        if scraper.login_status == 'logged_in':
            print("\nğŸ”„ æµ‹è¯•è·³è½¬åˆ°å•†å“æ¦œå•é¡µé¢...")
            success, msg = scraper.goto_product_rank()
            print(f"ç»“æœï¼š{msg}")
            
            if success:
                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(3)
                
                # æˆªå›¾
                print("\nğŸ“¸ æ¦œå•é¡µé¢æˆªå›¾...")
                screenshot_base64 = scraper.take_screenshot()
                if screenshot_base64:
                    print(f"âœ… æˆªå›¾æˆåŠŸï¼Base64é•¿åº¦ï¼š{len(screenshot_base64)} å­—ç¬¦")
                    
                    img_data = base64.b64decode(screenshot_base64)
                    img = Image.open(BytesIO(img_data))
                    img.save('test_screenshot_rank_page.png')
                    print("âœ… æˆªå›¾å·²ä¿å­˜ï¼štest_screenshot_rank_page.png")
                
                # æµ‹è¯•è·å–é€‰é¡¹
                print("\nğŸ”„ æµ‹è¯•è·å–æ¦œå•é€‰é¡¹...")
                options = scraper.get_all_rank_options()
                
                print("\nå¯ç”¨é€‰é¡¹ï¼š")
                print(f"  æ¦œå•ç±»å‹ï¼š{options.get('rank_types', [])}")
                print(f"  æ—¶é—´èŒƒå›´ï¼š{options.get('time_ranges', [])}")
                print(f"  è¡Œä¸šç±»ç›®ï¼š{options.get('categories', [])}")
                print(f"  å“ç‰Œç±»å‹ï¼š{options.get('brand_types', [])}")
                
                if not options['rank_types']:
                    print("\nâš ï¸  è­¦å‘Šï¼šæœªèƒ½è·å–æ¦œå•é€‰é¡¹ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å…ƒç´ å®šä½ï¼")
        
        print("\n" + "=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        print("\næµ‹è¯•ç»“æœï¼š")
        print(f"  ç™»å½•çŠ¶æ€ï¼š{scraper.login_status}")
        print(f"  å½“å‰URLï¼š{scraper.driver.current_url if scraper.driver else 'N/A'}")
        print(f"  æˆªå›¾åŠŸèƒ½ï¼š{'âœ… æ­£å¸¸' if screenshot_base64 else 'âŒ å¤±è´¥'}")
        
        # æš‚åœï¼Œè®©ç”¨æˆ·æŸ¥çœ‹
        input("\næŒ‰å›è½¦é”®å…³é—­æµè§ˆå™¨...")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯ï¼š{str(e)}")
        import traceback
        traceback.print_exc()
        
        input("\næŒ‰å›è½¦é”®å…³é—­æµè§ˆå™¨...")
    
    finally:
        print("\nğŸ”„ å…³é—­æµè§ˆå™¨...")
        scraper.close()
        print("âœ… æµ‹è¯•ç»“æŸ")

if __name__ == '__main__':
    main()

